{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Image_denoising.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"l0aEZ0ieTBC_","colab_type":"code","outputId":"e8163e37-aff5-4ddd-9f59-89e4d68254a4","executionInfo":{"status":"ok","timestamp":1556028564105,"user_tz":-330,"elapsed":140997,"user":{"displayName":"chhaya kumar das","photoUrl":"https://lh4.googleusercontent.com/-72S0CIJmkNQ/AAAAAAAAAAI/AAAAAAAAAP4/TOqLaMhUrd8/s64/photo.jpg","userId":"05135137199177257776"}},"colab":{"base_uri":"https://localhost:8080/","height":469}},"cell_type":"code","source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","!wget https://launchpad.net/~alessandro-strada/+archive/ubuntu/google-drive-ocamlfuse-beta/+build/15331130/+files/google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb\n","!dpkg -i google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb\n","!apt-get install -f\n","!apt-get -y install -qq fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":1,"outputs":[{"output_type":"stream","text":["E: Package 'python-software-properties' has no installation candidate\n","Selecting previously unselected package google-drive-ocamlfuse.\n","(Reading database ... 131304 files and directories currently installed.)\n","Preparing to unpack .../google-drive-ocamlfuse_0.7.3-0ubuntu3~ubuntu18.04.1_amd64.deb ...\n","Unpacking google-drive-ocamlfuse (0.7.3-0ubuntu3~ubuntu18.04.1) ...\n","Setting up google-drive-ocamlfuse (0.7.3-0ubuntu3~ubuntu18.04.1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","--2019-04-23 14:07:27--  https://launchpad.net/~alessandro-strada/+archive/ubuntu/google-drive-ocamlfuse-beta/+build/15331130/+files/google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb\n","Resolving launchpad.net (launchpad.net)... 91.189.89.222, 91.189.89.223, 2001:67c:1560:8003::8003, ...\n","Connecting to launchpad.net (launchpad.net)|91.189.89.222|:443... connected.\n","HTTP request sent, awaiting response... 404 Not Found\n","2019-04-23 14:07:27 ERROR 404: Not Found.\n","\n","\u001b[1mdpkg:\u001b[0m \u001b[1;31merror:\u001b[0m cannot access archive 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb': No such file or directory\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-410\n","Use 'apt autoremove' to remove it.\n","0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n"],"name":"stdout"}]},{"metadata":{"id":"8EyqSfUuD6kr","colab_type":"code","colab":{}},"cell_type":"code","source":["!mkdir -p drive\n","!google-drive-ocamlfuse drive"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3KhgILC9Edjc","colab_type":"code","outputId":"0bb922ae-62c1-4d0c-82df-f5239ba0d985","executionInfo":{"status":"ok","timestamp":1556028622439,"user_tz":-330,"elapsed":44091,"user":{"displayName":"chhaya kumar das","photoUrl":"https://lh4.googleusercontent.com/-72S0CIJmkNQ/AAAAAAAAAAI/AAAAAAAAAP4/TOqLaMhUrd8/s64/photo.jpg","userId":"05135137199177257776"}},"colab":{"base_uri":"https://localhost:8080/","height":538}},"cell_type":"code","source":["!pip install tensorflow-gpu==2.0.0-alpha0"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting tensorflow-gpu==2.0.0-alpha0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/66/32cffad095253219d53f6b6c2a436637bbe45ac4e7be0244557210dc3918/tensorflow_gpu-2.0.0a0-cp36-cp36m-manylinux1_x86_64.whl (332.1MB)\n","\u001b[K    100% |████████████████████████████████| 332.1MB 48kB/s \n","\u001b[?25hCollecting google-pasta>=0.1.2 (from tensorflow-gpu==2.0.0-alpha0)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/bb/f1bbc131d6294baa6085a222d29abadd012696b73dcbf8cf1bf56b9f082a/google_pasta-0.1.5-py3-none-any.whl (51kB)\n","\u001b[K    100% |████████████████████████████████| 61kB 25.3MB/s \n","\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.15.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.7.1)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.0.7)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.11.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.0.9)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.1.0)\n","Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.16.2)\n","Collecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301 (from tensorflow-gpu==2.0.0-alpha0)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl (3.0MB)\n","\u001b[K    100% |████████████████████████████████| 3.0MB 9.8MB/s \n","\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (3.7.1)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.7.1)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.2.2)\n","Collecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 (from tensorflow-gpu==2.0.0-alpha0)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl (411kB)\n","\u001b[K    100% |████████████████████████████████| 419kB 6.2MB/s \n","\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.33.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-alpha0) (2.8.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (3.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (0.15.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-alpha0) (40.9.0)\n","Installing collected packages: google-pasta, tb-nightly, tf-estimator-nightly, tensorflow-gpu\n","Successfully installed google-pasta-0.1.5 tb-nightly-1.14.0a20190301 tensorflow-gpu-2.0.0a0 tf-estimator-nightly-1.14.0.dev2019030115\n"],"name":"stdout"}]},{"metadata":{"id":"JirrewGQFNbw","colab_type":"code","colab":{}},"cell_type":"code","source":["import cv2\n","import tensorflow as tf\n","import numpy as np\n","from tqdm import tqdm\n","from sklearn.datasets import load_files\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-MOGOen2FedV","colab_type":"code","colab":{}},"cell_type":"code","source":["def load_data(path):\n","    data = load_files(path)\n","    files = np.array(data['filenames'])\n","    return files"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NnUK47UqLDBK","colab_type":"code","colab":{}},"cell_type":"code","source":["def ext_img(img):\n","    imag = cv2.imread(img)\n","    imag = cv2.cvtColor(imag,cv2.COLOR_BGR2GRAY)\n","    imag = imag/255\n","    imag = np.expand_dims(imag,axis=2)\n","    return imag"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Icp1QzgkL1_F","colab_type":"code","colab":{}},"cell_type":"code","source":["def tensor_4d(fil):\n","    lis = [ext_img(im) for im in tqdm(fil)]\n","    return np.stack(lis,axis=0)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YSzqRtp7MRe3","colab_type":"code","colab":{}},"cell_type":"code","source":["fold_path = 'drive/datasets/shapes'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"y5O9NJFxM10f","colab_type":"code","colab":{}},"cell_type":"code","source":["img_files = load_data(fold_path)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YSHV1x_dM7Up","colab_type":"code","outputId":"941ba070-6658-4a83-cbc3-92bdc8f3c0e1","executionInfo":{"status":"ok","timestamp":1556028902190,"user_tz":-330,"elapsed":2160,"user":{"displayName":"chhaya kumar das","photoUrl":"https://lh4.googleusercontent.com/-72S0CIJmkNQ/AAAAAAAAAAI/AAAAAAAAAP4/TOqLaMhUrd8/s64/photo.jpg","userId":"05135137199177257776"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["imgs = tensor_4d(img_files)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["100%|██████████| 300/300 [00:01<00:00, 211.54it/s]\n"],"name":"stderr"}]},{"metadata":{"id":"hmfINCH6PBAs","colab_type":"code","outputId":"f5a3a7c3-72b0-4543-d7d9-756c0d707734","executionInfo":{"status":"ok","timestamp":1556028905267,"user_tz":-330,"elapsed":977,"user":{"displayName":"chhaya kumar das","photoUrl":"https://lh4.googleusercontent.com/-72S0CIJmkNQ/AAAAAAAAAAI/AAAAAAAAAP4/TOqLaMhUrd8/s64/photo.jpg","userId":"05135137199177257776"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["imgs.shape"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(300, 28, 28, 1)"]},"metadata":{"tags":[]},"execution_count":11}]},{"metadata":{"id":"hsdxwNUdQuoT","colab_type":"code","colab":{}},"cell_type":"code","source":["class Encoder(tf.keras.layers.Layer):\n","    \n","    def __init__(self):\n","        super(Encoder,self).__init__()\n","        self.conv8 = tf.keras.layers.Conv2D(8,3,activation=tf.nn.relu,strides=(1,1),padding='SAME')\n","        self.conv16 = tf.keras.layers.Conv2D(16,3,activation=tf.nn.relu,strides=(1,1),padding='SAME')\n","        self.conv32 = tf.keras.layers.Conv2D(32,3,activation=tf.nn.relu,strides=(1,1),padding='SAME')\n","        self.max_pool_1 = tf.keras.layers.MaxPooling2D(pool_size=(2,2),strides=(2,2))\n","        self.max_pool_2 = tf.keras.layers.MaxPooling2D(pool_size=(2,2),strides=(2,2))\n","        \n","    def call(self,inp):\n","        x = self.conv32(inp)\n","        x = self.max_pool_1(x)\n","        x = self.conv16(x)\n","        x = self.max_pool_2(x)\n","        x = self.conv8(x)\n","        return x\n","        \n","        \n","        "],"execution_count":0,"outputs":[]},{"metadata":{"id":"YUgVDH9w4ZUC","colab_type":"code","colab":{}},"cell_type":"code","source":["class Decoder(tf.keras.layers.Layer):\n","    \n","    def __init__(self):\n","        super(Decoder,self).__init__()\n","        self.convtr8 = tf.keras.layers.Conv2DTranspose(8,3,strides=(1,1),padding='SAME',activation=tf.nn.relu)\n","        self.convtr16 = tf.keras.layers.Conv2DTranspose(16,3,strides=(1,1),padding='SAME',activation=tf.nn.relu)\n","        self.convtr32 = tf.keras.layers.Conv2DTranspose(32,3,strides=(1,1),padding='SAME',activation=tf.nn.relu)\n","        self.convtr1 = tf.keras.layers.Conv2DTranspose(1,3,strides=(1,1),padding='SAME',activation=tf.nn.relu)\n","        self.upsample_1 = tf.keras.layers.UpSampling2D(size=(2,2))\n","        self.upsample_2 = tf.keras.layers.UpSampling2D(size=(2,2))\n","        \n","    def call(self,inp):\n","        x = self.convtr8(inp)\n","        x = self.upsample_1(x)\n","        x = self.convtr16(x)\n","        x = self.upsample_2(x)\n","        x = self.convtr32(x)\n","        x = self.convtr1(x)\n","        return x\n","        "],"execution_count":0,"outputs":[]},{"metadata":{"id":"7Dxgg9sVARBN","colab_type":"code","colab":{}},"cell_type":"code","source":["class Autoencoder(tf.keras.Model):\n","    \n","    def __init__(self):\n","        super(Autoencoder,self).__init__()\n","        self.encode = Encoder()\n","        self.decode = Decoder()\n","        \n","    def call(self,inputs):\n","        encoded = self.encode(inputs)\n","        decoded = self.decode(encoded)\n","        return decoded"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mnxhgVfaATLi","colab_type":"code","colab":{}},"cell_type":"code","source":["ae = Autoencoder()\n","        "],"execution_count":0,"outputs":[]},{"metadata":{"id":"jKmGrdvPkYl5","colab_type":"code","colab":{}},"cell_type":"code","source":["optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n","mse_loss_fn = tf.keras.losses.MeanSquaredError()\n","loss_metric = tf.keras.metrics.Mean()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IW38Rwchmxfj","colab_type":"code","colab":{}},"cell_type":"code","source":["ae = Autoencoder()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CM0IY2W5nPEN","colab_type":"code","outputId":"7d5acbc7-fe45-45af-881b-27ef3c9df331","executionInfo":{"status":"ok","timestamp":1556030123307,"user_tz":-330,"elapsed":366730,"user":{"displayName":"chhaya kumar das","photoUrl":"https://lh4.googleusercontent.com/-72S0CIJmkNQ/AAAAAAAAAAI/AAAAAAAAAP4/TOqLaMhUrd8/s64/photo.jpg","userId":"05135137199177257776"}},"colab":{"base_uri":"https://localhost:8080/","height":27665}},"cell_type":"code","source":["for epoch in range(400):\n","    print('Start of epoch %d' % (epoch,))\n","\n","    for start,end in zip(range(0,len(imgs),10),range(10,len(imgs),10)):\n","        xtr = imgs[start:end]\n","        xtr = xtr.astype('float32')\n","        noi = xtr + 0.5*np.random.randn(*xtr.shape)\n","        noi = np.clip(noi,0.,1.)\n","        with tf.GradientTape() as tape:\n","            recon = ae(noi)\n","            loss = mse_loss_fn(xtr, recon)\n","\n","        grads = tape.gradient(loss, ae.trainable_variables)\n","        optimizer.apply_gradients(zip(grads, ae.trainable_variables))\n","\n","        loss_metric(loss)\n","\n","        if start % 100 == 0:\n","            print('step %s: mean loss = %s' % (start, loss_metric.result().numpy()))"],"execution_count":43,"outputs":[{"output_type":"stream","text":["Start of epoch 0\n","step 0: mean loss = 0.020298984\n","step 100: mean loss = 0.020284552\n","step 200: mean loss = 0.020266693\n","Start of epoch 1\n","step 0: mean loss = 0.020251129\n","step 100: mean loss = 0.020236045\n","step 200: mean loss = 0.020219589\n","Start of epoch 2\n","step 0: mean loss = 0.020205155\n","step 100: mean loss = 0.020190742\n","step 200: mean loss = 0.020174533\n","Start of epoch 3\n","step 0: mean loss = 0.020161161\n","step 100: mean loss = 0.02014642\n","step 200: mean loss = 0.020130903\n","Start of epoch 4\n","step 0: mean loss = 0.020117644\n","step 100: mean loss = 0.020102317\n","step 200: mean loss = 0.020087527\n","Start of epoch 5\n","step 0: mean loss = 0.02007372\n","step 100: mean loss = 0.020059902\n","step 200: mean loss = 0.02004338\n","Start of epoch 6\n","step 0: mean loss = 0.020030128\n","step 100: mean loss = 0.02001627\n","step 200: mean loss = 0.02000067\n","Start of epoch 7\n","step 0: mean loss = 0.0199869\n","step 100: mean loss = 0.019972553\n","step 200: mean loss = 0.019957287\n","Start of epoch 8\n","step 0: mean loss = 0.019943604\n","step 100: mean loss = 0.019929105\n","step 200: mean loss = 0.019914242\n","Start of epoch 9\n","step 0: mean loss = 0.019901624\n","step 100: mean loss = 0.0198887\n","step 200: mean loss = 0.01987407\n","Start of epoch 10\n","step 0: mean loss = 0.019860443\n","step 100: mean loss = 0.01984756\n","step 200: mean loss = 0.01983297\n","Start of epoch 11\n","step 0: mean loss = 0.019820713\n","step 100: mean loss = 0.019809235\n","step 200: mean loss = 0.019793916\n","Start of epoch 12\n","step 0: mean loss = 0.019780353\n","step 100: mean loss = 0.019767292\n","step 200: mean loss = 0.019753663\n","Start of epoch 13\n","step 0: mean loss = 0.019741656\n","step 100: mean loss = 0.019727884\n","step 200: mean loss = 0.019713806\n","Start of epoch 14\n","step 0: mean loss = 0.0197009\n","step 100: mean loss = 0.019688534\n","step 200: mean loss = 0.01967426\n","Start of epoch 15\n","step 0: mean loss = 0.01966232\n","step 100: mean loss = 0.019648738\n","step 200: mean loss = 0.019634573\n","Start of epoch 16\n","step 0: mean loss = 0.019621849\n","step 100: mean loss = 0.019608706\n","step 200: mean loss = 0.019594\n","Start of epoch 17\n","step 0: mean loss = 0.0195823\n","step 100: mean loss = 0.019570516\n","step 200: mean loss = 0.019556483\n","Start of epoch 18\n","step 0: mean loss = 0.019543571\n","step 100: mean loss = 0.019530857\n","step 200: mean loss = 0.019517219\n","Start of epoch 19\n","step 0: mean loss = 0.019504566\n","step 100: mean loss = 0.01949162\n","step 200: mean loss = 0.019477531\n","Start of epoch 20\n","step 0: mean loss = 0.01946659\n","step 100: mean loss = 0.019453764\n","step 200: mean loss = 0.019439952\n","Start of epoch 21\n","step 0: mean loss = 0.0194288\n","step 100: mean loss = 0.019416353\n","step 200: mean loss = 0.01940307\n","Start of epoch 22\n","step 0: mean loss = 0.019390643\n","step 100: mean loss = 0.019377341\n","step 200: mean loss = 0.019363426\n","Start of epoch 23\n","step 0: mean loss = 0.019351957\n","step 100: mean loss = 0.019341055\n","step 200: mean loss = 0.019327687\n","Start of epoch 24\n","step 0: mean loss = 0.019316524\n","step 100: mean loss = 0.019305281\n","step 200: mean loss = 0.019291177\n","Start of epoch 25\n","step 0: mean loss = 0.019280672\n","step 100: mean loss = 0.019269064\n","step 200: mean loss = 0.01925582\n","Start of epoch 26\n","step 0: mean loss = 0.019245071\n","step 100: mean loss = 0.019232322\n","step 200: mean loss = 0.019219328\n","Start of epoch 27\n","step 0: mean loss = 0.019208115\n","step 100: mean loss = 0.019196704\n","step 200: mean loss = 0.019183872\n","Start of epoch 28\n","step 0: mean loss = 0.019174205\n","step 100: mean loss = 0.019162238\n","step 200: mean loss = 0.019149743\n","Start of epoch 29\n","step 0: mean loss = 0.019138467\n","step 100: mean loss = 0.019126276\n","step 200: mean loss = 0.019114237\n","Start of epoch 30\n","step 0: mean loss = 0.019103661\n","step 100: mean loss = 0.019093156\n","step 200: mean loss = 0.019080434\n","Start of epoch 31\n","step 0: mean loss = 0.019069776\n","step 100: mean loss = 0.01905888\n","step 200: mean loss = 0.019046994\n","Start of epoch 32\n","step 0: mean loss = 0.019035935\n","step 100: mean loss = 0.019025754\n","step 200: mean loss = 0.019013299\n","Start of epoch 33\n","step 0: mean loss = 0.019002795\n","step 100: mean loss = 0.018992856\n","step 200: mean loss = 0.018981421\n","Start of epoch 34\n","step 0: mean loss = 0.018970663\n","step 100: mean loss = 0.018960085\n","step 200: mean loss = 0.018949136\n","Start of epoch 35\n","step 0: mean loss = 0.018938553\n","step 100: mean loss = 0.018927554\n","step 200: mean loss = 0.018915538\n","Start of epoch 36\n","step 0: mean loss = 0.018905934\n","step 100: mean loss = 0.018896084\n","step 200: mean loss = 0.018883321\n","Start of epoch 37\n","step 0: mean loss = 0.018872425\n","step 100: mean loss = 0.018861625\n","step 200: mean loss = 0.01885045\n","Start of epoch 38\n","step 0: mean loss = 0.018840583\n","step 100: mean loss = 0.018830953\n","step 200: mean loss = 0.018819036\n","Start of epoch 39\n","step 0: mean loss = 0.01880956\n","step 100: mean loss = 0.018799134\n","step 200: mean loss = 0.018787693\n","Start of epoch 40\n","step 0: mean loss = 0.018778294\n","step 100: mean loss = 0.018768478\n","step 200: mean loss = 0.018756954\n","Start of epoch 41\n","step 0: mean loss = 0.018746398\n","step 100: mean loss = 0.018736353\n","step 200: mean loss = 0.018724186\n","Start of epoch 42\n","step 0: mean loss = 0.018714838\n","step 100: mean loss = 0.018705187\n","step 200: mean loss = 0.018694615\n","Start of epoch 43\n","step 0: mean loss = 0.018685171\n","step 100: mean loss = 0.018675825\n","step 200: mean loss = 0.018664522\n","Start of epoch 44\n","step 0: mean loss = 0.018655354\n","step 100: mean loss = 0.018645259\n","step 200: mean loss = 0.018634345\n","Start of epoch 45\n","step 0: mean loss = 0.018624626\n","step 100: mean loss = 0.018614698\n","step 200: mean loss = 0.018603759\n","Start of epoch 46\n","step 0: mean loss = 0.018595185\n","step 100: mean loss = 0.018584998\n","step 200: mean loss = 0.018573027\n","Start of epoch 47\n","step 0: mean loss = 0.018563423\n","step 100: mean loss = 0.018554283\n","step 200: mean loss = 0.018544061\n","Start of epoch 48\n","step 0: mean loss = 0.018534428\n","step 100: mean loss = 0.018525101\n","step 200: mean loss = 0.018514995\n","Start of epoch 49\n","step 0: mean loss = 0.018506039\n","step 100: mean loss = 0.018496763\n","step 200: mean loss = 0.018485796\n","Start of epoch 50\n","step 0: mean loss = 0.018476503\n","step 100: mean loss = 0.018468294\n","step 200: mean loss = 0.018457282\n","Start of epoch 51\n","step 0: mean loss = 0.018448288\n","step 100: mean loss = 0.01843863\n","step 200: mean loss = 0.018428078\n","Start of epoch 52\n","step 0: mean loss = 0.018419271\n","step 100: mean loss = 0.018410586\n","step 200: mean loss = 0.018401202\n","Start of epoch 53\n","step 0: mean loss = 0.0183929\n","step 100: mean loss = 0.018384822\n","step 200: mean loss = 0.018373964\n","Start of epoch 54\n","step 0: mean loss = 0.01836506\n","step 100: mean loss = 0.018356217\n","step 200: mean loss = 0.018345553\n","Start of epoch 55\n","step 0: mean loss = 0.018337937\n","step 100: mean loss = 0.01832931\n","step 200: mean loss = 0.018320203\n","Start of epoch 56\n","step 0: mean loss = 0.018311515\n","step 100: mean loss = 0.018302502\n","step 200: mean loss = 0.018293196\n","Start of epoch 57\n","step 0: mean loss = 0.018284328\n","step 100: mean loss = 0.018276252\n","step 200: mean loss = 0.01826648\n","Start of epoch 58\n","step 0: mean loss = 0.018257776\n","step 100: mean loss = 0.018248867\n","step 200: mean loss = 0.018238576\n","Start of epoch 59\n","step 0: mean loss = 0.018230254\n","step 100: mean loss = 0.018221153\n","step 200: mean loss = 0.018211298\n","Start of epoch 60\n","step 0: mean loss = 0.018201852\n","step 100: mean loss = 0.018192777\n","step 200: mean loss = 0.018182727\n","Start of epoch 61\n","step 0: mean loss = 0.018173557\n","step 100: mean loss = 0.01816525\n","step 200: mean loss = 0.018156167\n","Start of epoch 62\n","step 0: mean loss = 0.018147953\n","step 100: mean loss = 0.018139381\n","step 200: mean loss = 0.018129932\n","Start of epoch 63\n","step 0: mean loss = 0.018121205\n","step 100: mean loss = 0.018112976\n","step 200: mean loss = 0.018103218\n","Start of epoch 64\n","step 0: mean loss = 0.018094415\n","step 100: mean loss = 0.018086644\n","step 200: mean loss = 0.018077765\n","Start of epoch 65\n","step 0: mean loss = 0.01807009\n","step 100: mean loss = 0.01806186\n","step 200: mean loss = 0.018051771\n","Start of epoch 66\n","step 0: mean loss = 0.018043669\n","step 100: mean loss = 0.018035738\n","step 200: mean loss = 0.01802562\n","Start of epoch 67\n","step 0: mean loss = 0.0180177\n","step 100: mean loss = 0.01800896\n","step 200: mean loss = 0.017999526\n","Start of epoch 68\n","step 0: mean loss = 0.01799179\n","step 100: mean loss = 0.017984202\n","step 200: mean loss = 0.01797414\n","Start of epoch 69\n","step 0: mean loss = 0.017966315\n","step 100: mean loss = 0.01795897\n","step 200: mean loss = 0.017949648\n","Start of epoch 70\n","step 0: mean loss = 0.017941926\n","step 100: mean loss = 0.017933832\n","step 200: mean loss = 0.017924989\n","Start of epoch 71\n","step 0: mean loss = 0.01791706\n","step 100: mean loss = 0.017909473\n","step 200: mean loss = 0.01790067\n","Start of epoch 72\n","step 0: mean loss = 0.017893197\n","step 100: mean loss = 0.017885076\n","step 200: mean loss = 0.017876346\n","Start of epoch 73\n","step 0: mean loss = 0.017869195\n","step 100: mean loss = 0.017861413\n","step 200: mean loss = 0.017852185\n","Start of epoch 74\n","step 0: mean loss = 0.017844632\n","step 100: mean loss = 0.017837595\n","step 200: mean loss = 0.017828666\n","Start of epoch 75\n","step 0: mean loss = 0.017820865\n","step 100: mean loss = 0.017812725\n","step 200: mean loss = 0.017803939\n","Start of epoch 76\n","step 0: mean loss = 0.017796045\n","step 100: mean loss = 0.01778864\n","step 200: mean loss = 0.017779436\n","Start of epoch 77\n","step 0: mean loss = 0.017772341\n","step 100: mean loss = 0.017765347\n","step 200: mean loss = 0.017756978\n","Start of epoch 78\n","step 0: mean loss = 0.017749187\n","step 100: mean loss = 0.017741922\n","step 200: mean loss = 0.017733596\n","Start of epoch 79\n","step 0: mean loss = 0.017726324\n","step 100: mean loss = 0.017719386\n","step 200: mean loss = 0.017711272\n","Start of epoch 80\n","step 0: mean loss = 0.017704733\n","step 100: mean loss = 0.017697666\n","step 200: mean loss = 0.017689353\n","Start of epoch 81\n","step 0: mean loss = 0.017682604\n","step 100: mean loss = 0.017674709\n","step 200: mean loss = 0.01766651\n","Start of epoch 82\n","step 0: mean loss = 0.0176597\n","step 100: mean loss = 0.01765189\n","step 200: mean loss = 0.017643197\n","Start of epoch 83\n","step 0: mean loss = 0.017635662\n","step 100: mean loss = 0.017628027\n","step 200: mean loss = 0.01762047\n","Start of epoch 84\n","step 0: mean loss = 0.017614044\n","step 100: mean loss = 0.017606698\n","step 200: mean loss = 0.017598197\n","Start of epoch 85\n","step 0: mean loss = 0.017591553\n","step 100: mean loss = 0.017584769\n","step 200: mean loss = 0.01757669\n","Start of epoch 86\n","step 0: mean loss = 0.01756998\n","step 100: mean loss = 0.017563285\n","step 200: mean loss = 0.017555542\n","Start of epoch 87\n","step 0: mean loss = 0.017547982\n","step 100: mean loss = 0.01754092\n","step 200: mean loss = 0.017533017\n","Start of epoch 88\n","step 0: mean loss = 0.017526664\n","step 100: mean loss = 0.017518986\n","step 200: mean loss = 0.017510371\n","Start of epoch 89\n","step 0: mean loss = 0.017503982\n","step 100: mean loss = 0.017497249\n","step 200: mean loss = 0.017489273\n","Start of epoch 90\n","step 0: mean loss = 0.0174825\n","step 100: mean loss = 0.017474962\n","step 200: mean loss = 0.01746668\n","Start of epoch 91\n","step 0: mean loss = 0.017459223\n","step 100: mean loss = 0.017452992\n","step 200: mean loss = 0.017444523\n","Start of epoch 92\n","step 0: mean loss = 0.017438136\n","step 100: mean loss = 0.017432302\n","step 200: mean loss = 0.017424712\n","Start of epoch 93\n","step 0: mean loss = 0.017417476\n","step 100: mean loss = 0.017411083\n","step 200: mean loss = 0.01740246\n","Start of epoch 94\n","step 0: mean loss = 0.017395914\n","step 100: mean loss = 0.017389288\n","step 200: mean loss = 0.017381001\n","Start of epoch 95\n","step 0: mean loss = 0.017375376\n","step 100: mean loss = 0.017369349\n","step 200: mean loss = 0.017361736\n","Start of epoch 96\n","step 0: mean loss = 0.017355481\n","step 100: mean loss = 0.017348533\n","step 200: mean loss = 0.017340498\n","Start of epoch 97\n","step 0: mean loss = 0.017333442\n","step 100: mean loss = 0.017326947\n","step 200: mean loss = 0.01731916\n","Start of epoch 98\n","step 0: mean loss = 0.017312644\n","step 100: mean loss = 0.017306127\n","step 200: mean loss = 0.017298367\n","Start of epoch 99\n","step 0: mean loss = 0.01729185\n","step 100: mean loss = 0.017285371\n","step 200: mean loss = 0.017278211\n","Start of epoch 100\n","step 0: mean loss = 0.017271511\n","step 100: mean loss = 0.017265001\n","step 200: mean loss = 0.017257001\n","Start of epoch 101\n","step 0: mean loss = 0.017250674\n","step 100: mean loss = 0.017243814\n","step 200: mean loss = 0.01723569\n","Start of epoch 102\n","step 0: mean loss = 0.017229017\n","step 100: mean loss = 0.017222079\n","step 200: mean loss = 0.017214363\n","Start of epoch 103\n","step 0: mean loss = 0.017208189\n","step 100: mean loss = 0.017201727\n","step 200: mean loss = 0.017194293\n","Start of epoch 104\n","step 0: mean loss = 0.017187955\n","step 100: mean loss = 0.017181147\n","step 200: mean loss = 0.017174173\n","Start of epoch 105\n","step 0: mean loss = 0.017168187\n","step 100: mean loss = 0.017161775\n","step 200: mean loss = 0.017154329\n","Start of epoch 106\n","step 0: mean loss = 0.017147953\n","step 100: mean loss = 0.01714142\n","step 200: mean loss = 0.017134363\n","Start of epoch 107\n","step 0: mean loss = 0.01712848\n","step 100: mean loss = 0.017123062\n","step 200: mean loss = 0.017116232\n","Start of epoch 108\n","step 0: mean loss = 0.017109685\n","step 100: mean loss = 0.017103955\n","step 200: mean loss = 0.017096542\n","Start of epoch 109\n","step 0: mean loss = 0.017090261\n","step 100: mean loss = 0.017084511\n","step 200: mean loss = 0.017077979\n","Start of epoch 110\n","step 0: mean loss = 0.017072035\n","step 100: mean loss = 0.017066296\n","step 200: mean loss = 0.017058542\n","Start of epoch 111\n","step 0: mean loss = 0.017052405\n","step 100: mean loss = 0.017046783\n","step 200: mean loss = 0.017040012\n","Start of epoch 112\n","step 0: mean loss = 0.017034458\n","step 100: mean loss = 0.017028566\n","step 200: mean loss = 0.017021714\n","Start of epoch 113\n","step 0: mean loss = 0.017016297\n","step 100: mean loss = 0.017010028\n","step 200: mean loss = 0.017003443\n","Start of epoch 114\n","step 0: mean loss = 0.016997611\n","step 100: mean loss = 0.016991856\n","step 200: mean loss = 0.01698458\n","Start of epoch 115\n","step 0: mean loss = 0.016978731\n","step 100: mean loss = 0.016972736\n","step 200: mean loss = 0.01696623\n","Start of epoch 116\n","step 0: mean loss = 0.016960813\n","step 100: mean loss = 0.016955163\n","step 200: mean loss = 0.016947279\n","Start of epoch 117\n","step 0: mean loss = 0.016941579\n","step 100: mean loss = 0.016935281\n","step 200: mean loss = 0.016928889\n","Start of epoch 118\n","step 0: mean loss = 0.016923435\n","step 100: mean loss = 0.016917348\n","step 200: mean loss = 0.016910015\n","Start of epoch 119\n","step 0: mean loss = 0.016904287\n","step 100: mean loss = 0.016898334\n","step 200: mean loss = 0.0168913\n","Start of epoch 120\n","step 0: mean loss = 0.01688496\n","step 100: mean loss = 0.016879149\n","step 200: mean loss = 0.01687257\n","Start of epoch 121\n","step 0: mean loss = 0.016868135\n","step 100: mean loss = 0.016862491\n","step 200: mean loss = 0.016855327\n","Start of epoch 122\n","step 0: mean loss = 0.016849663\n","step 100: mean loss = 0.01684442\n","step 200: mean loss = 0.01683802\n","Start of epoch 123\n","step 0: mean loss = 0.016832467\n","step 100: mean loss = 0.016826743\n","step 200: mean loss = 0.016820047\n","Start of epoch 124\n","step 0: mean loss = 0.016814737\n","step 100: mean loss = 0.01680826\n","step 200: mean loss = 0.0168015\n","Start of epoch 125\n","step 0: mean loss = 0.01679528\n","step 100: mean loss = 0.016790194\n","step 200: mean loss = 0.016783139\n","Start of epoch 126\n","step 0: mean loss = 0.016777296\n","step 100: mean loss = 0.016771521\n","step 200: mean loss = 0.016764948\n","Start of epoch 127\n","step 0: mean loss = 0.016759397\n","step 100: mean loss = 0.016753908\n","step 200: mean loss = 0.016747471\n","Start of epoch 128\n","step 0: mean loss = 0.016741902\n","step 100: mean loss = 0.016736114\n","step 200: mean loss = 0.016729958\n","Start of epoch 129\n","step 0: mean loss = 0.016724516\n","step 100: mean loss = 0.016719226\n","step 200: mean loss = 0.016713131\n","Start of epoch 130\n","step 0: mean loss = 0.016708564\n","step 100: mean loss = 0.016704919\n","step 200: mean loss = 0.016698852\n","Start of epoch 131\n","step 0: mean loss = 0.016693648\n","step 100: mean loss = 0.016687695\n","step 200: mean loss = 0.016680993\n","Start of epoch 132\n","step 0: mean loss = 0.016675863\n","step 100: mean loss = 0.0166712\n","step 200: mean loss = 0.016665358\n","Start of epoch 133\n","step 0: mean loss = 0.016660556\n","step 100: mean loss = 0.016655123\n","step 200: mean loss = 0.01664952\n","Start of epoch 134\n","step 0: mean loss = 0.016643649\n","step 100: mean loss = 0.016637938\n","step 200: mean loss = 0.016631965\n","Start of epoch 135\n","step 0: mean loss = 0.016627127\n","step 100: mean loss = 0.016622325\n","step 200: mean loss = 0.01661595\n","Start of epoch 136\n","step 0: mean loss = 0.016611263\n","step 100: mean loss = 0.016605917\n","step 200: mean loss = 0.016600616\n","Start of epoch 137\n","step 0: mean loss = 0.016596068\n","step 100: mean loss = 0.016590644\n","step 200: mean loss = 0.016584175\n","Start of epoch 138\n","step 0: mean loss = 0.016579265\n","step 100: mean loss = 0.016574167\n","step 200: mean loss = 0.016568488\n","Start of epoch 139\n","step 0: mean loss = 0.016563734\n","step 100: mean loss = 0.016558658\n","step 200: mean loss = 0.01655291\n","Start of epoch 140\n","step 0: mean loss = 0.016548118\n","step 100: mean loss = 0.016542358\n","step 200: mean loss = 0.01653659\n","Start of epoch 141\n","step 0: mean loss = 0.016531184\n","step 100: mean loss = 0.01652631\n","step 200: mean loss = 0.016520603\n","Start of epoch 142\n","step 0: mean loss = 0.016516004\n","step 100: mean loss = 0.016511416\n","step 200: mean loss = 0.016505623\n","Start of epoch 143\n","step 0: mean loss = 0.016499916\n","step 100: mean loss = 0.016494283\n","step 200: mean loss = 0.016488388\n","Start of epoch 144\n","step 0: mean loss = 0.01648367\n","step 100: mean loss = 0.01647855\n","step 200: mean loss = 0.016473062\n","Start of epoch 145\n","step 0: mean loss = 0.016468357\n","step 100: mean loss = 0.016463814\n","step 200: mean loss = 0.016458116\n","Start of epoch 146\n","step 0: mean loss = 0.016454082\n","step 100: mean loss = 0.016448941\n","step 200: mean loss = 0.01644251\n","Start of epoch 147\n","step 0: mean loss = 0.016437741\n","step 100: mean loss = 0.016432712\n","step 200: mean loss = 0.016427098\n","Start of epoch 148\n","step 0: mean loss = 0.016421976\n","step 100: mean loss = 0.016416764\n","step 200: mean loss = 0.016411195\n","Start of epoch 149\n","step 0: mean loss = 0.016406054\n","step 100: mean loss = 0.0164014\n","step 200: mean loss = 0.01639548\n","Start of epoch 150\n","step 0: mean loss = 0.016390342\n","step 100: mean loss = 0.01638485\n","step 200: mean loss = 0.016378574\n","Start of epoch 151\n","step 0: mean loss = 0.016374087\n","step 100: mean loss = 0.01636959\n","step 200: mean loss = 0.016364655\n","Start of epoch 152\n","step 0: mean loss = 0.01636028\n","step 100: mean loss = 0.016355384\n","step 200: mean loss = 0.016350193\n","Start of epoch 153\n","step 0: mean loss = 0.016345527\n","step 100: mean loss = 0.016341094\n","step 200: mean loss = 0.016335545\n","Start of epoch 154\n","step 0: mean loss = 0.01633151\n","step 100: mean loss = 0.01632659\n","step 200: mean loss = 0.016320642\n","Start of epoch 155\n","step 0: mean loss = 0.016315922\n","step 100: mean loss = 0.016311428\n","step 200: mean loss = 0.016305784\n","Start of epoch 156\n","step 0: mean loss = 0.016301135\n","step 100: mean loss = 0.016296681\n","step 200: mean loss = 0.016291182\n","Start of epoch 157\n","step 0: mean loss = 0.01628604\n","step 100: mean loss = 0.016282327\n","step 200: mean loss = 0.016276708\n","Start of epoch 158\n","step 0: mean loss = 0.016272172\n","step 100: mean loss = 0.016267026\n","step 200: mean loss = 0.016261945\n","Start of epoch 159\n","step 0: mean loss = 0.016257131\n","step 100: mean loss = 0.016252344\n","step 200: mean loss = 0.016246941\n","Start of epoch 160\n","step 0: mean loss = 0.016242329\n","step 100: mean loss = 0.016237518\n","step 200: mean loss = 0.016232012\n","Start of epoch 161\n","step 0: mean loss = 0.016227694\n","step 100: mean loss = 0.016223086\n","step 200: mean loss = 0.016217502\n","Start of epoch 162\n","step 0: mean loss = 0.016212918\n","step 100: mean loss = 0.016209036\n","step 200: mean loss = 0.016203832\n","Start of epoch 163\n","step 0: mean loss = 0.01619964\n","step 100: mean loss = 0.01619496\n","step 200: mean loss = 0.016189748\n","Start of epoch 164\n","step 0: mean loss = 0.016184872\n","step 100: mean loss = 0.016181193\n","step 200: mean loss = 0.016175436\n","Start of epoch 165\n","step 0: mean loss = 0.016170893\n","step 100: mean loss = 0.016166078\n","step 200: mean loss = 0.016160818\n","Start of epoch 166\n","step 0: mean loss = 0.016156822\n","step 100: mean loss = 0.016152048\n","step 200: mean loss = 0.016147342\n","Start of epoch 167\n","step 0: mean loss = 0.01614366\n","step 100: mean loss = 0.016139105\n","step 200: mean loss = 0.016134288\n","Start of epoch 168\n","step 0: mean loss = 0.016130114\n","step 100: mean loss = 0.01612553\n","step 200: mean loss = 0.016120816\n","Start of epoch 169\n","step 0: mean loss = 0.016116498\n","step 100: mean loss = 0.0161113\n","step 200: mean loss = 0.01610581\n","Start of epoch 170\n","step 0: mean loss = 0.016101826\n","step 100: mean loss = 0.016097529\n","step 200: mean loss = 0.016091356\n","Start of epoch 171\n","step 0: mean loss = 0.016086617\n","step 100: mean loss = 0.016082799\n","step 200: mean loss = 0.01607796\n","Start of epoch 172\n","step 0: mean loss = 0.016074035\n","step 100: mean loss = 0.016070183\n","step 200: mean loss = 0.016065072\n","Start of epoch 173\n","step 0: mean loss = 0.016060872\n","step 100: mean loss = 0.016056208\n","step 200: mean loss = 0.016050648\n","Start of epoch 174\n","step 0: mean loss = 0.016046116\n","step 100: mean loss = 0.016041769\n","step 200: mean loss = 0.016035976\n","Start of epoch 175\n","step 0: mean loss = 0.016032051\n","step 100: mean loss = 0.01602804\n","step 200: mean loss = 0.016022969\n","Start of epoch 176\n","step 0: mean loss = 0.016018646\n","step 100: mean loss = 0.01601425\n","step 200: mean loss = 0.016009355\n","Start of epoch 177\n","step 0: mean loss = 0.016005004\n","step 100: mean loss = 0.016000835\n","step 200: mean loss = 0.015996138\n","Start of epoch 178\n","step 0: mean loss = 0.015992057\n","step 100: mean loss = 0.015987994\n","step 200: mean loss = 0.015982933\n","Start of epoch 179\n","step 0: mean loss = 0.015978768\n","step 100: mean loss = 0.01597454\n","step 200: mean loss = 0.015969275\n","Start of epoch 180\n","step 0: mean loss = 0.01596488\n","step 100: mean loss = 0.015961127\n","step 200: mean loss = 0.015955994\n","Start of epoch 181\n","step 0: mean loss = 0.01595237\n","step 100: mean loss = 0.01594844\n","step 200: mean loss = 0.015944371\n","Start of epoch 182\n","step 0: mean loss = 0.015940227\n","step 100: mean loss = 0.015936468\n","step 200: mean loss = 0.015931446\n","Start of epoch 183\n","step 0: mean loss = 0.015927479\n","step 100: mean loss = 0.015923116\n","step 200: mean loss = 0.015917843\n","Start of epoch 184\n","step 0: mean loss = 0.015913483\n","step 100: mean loss = 0.015908945\n","step 200: mean loss = 0.015904123\n","Start of epoch 185\n","step 0: mean loss = 0.015900664\n","step 100: mean loss = 0.01589693\n","step 200: mean loss = 0.015892297\n","Start of epoch 186\n","step 0: mean loss = 0.015888112\n","step 100: mean loss = 0.01588482\n","step 200: mean loss = 0.01588042\n","Start of epoch 187\n","step 0: mean loss = 0.01587597\n","step 100: mean loss = 0.015871847\n","step 200: mean loss = 0.015867038\n","Start of epoch 188\n","step 0: mean loss = 0.015863223\n","step 100: mean loss = 0.015859917\n","step 200: mean loss = 0.01585503\n","Start of epoch 189\n","step 0: mean loss = 0.015851965\n","step 100: mean loss = 0.015848693\n","step 200: mean loss = 0.01584411\n","Start of epoch 190\n","step 0: mean loss = 0.015839946\n","step 100: mean loss = 0.015835887\n","step 200: mean loss = 0.015831286\n","Start of epoch 191\n","step 0: mean loss = 0.015827177\n","step 100: mean loss = 0.01582287\n","step 200: mean loss = 0.015818799\n","Start of epoch 192\n","step 0: mean loss = 0.015815048\n","step 100: mean loss = 0.015810838\n","step 200: mean loss = 0.015805695\n","Start of epoch 193\n","step 0: mean loss = 0.015801718\n","step 100: mean loss = 0.015797665\n","step 200: mean loss = 0.015793437\n","Start of epoch 194\n","step 0: mean loss = 0.015789408\n","step 100: mean loss = 0.015785832\n","step 200: mean loss = 0.01578104\n","Start of epoch 195\n","step 0: mean loss = 0.015777256\n","step 100: mean loss = 0.015773606\n","step 200: mean loss = 0.015769413\n","Start of epoch 196\n","step 0: mean loss = 0.015765961\n","step 100: mean loss = 0.015762394\n","step 200: mean loss = 0.015758097\n","Start of epoch 197\n","step 0: mean loss = 0.015754113\n","step 100: mean loss = 0.015750661\n","step 200: mean loss = 0.015746111\n","Start of epoch 198\n","step 0: mean loss = 0.015742354\n","step 100: mean loss = 0.015738636\n","step 200: mean loss = 0.015733793\n","Start of epoch 199\n","step 0: mean loss = 0.015729582\n","step 100: mean loss = 0.015725892\n","step 200: mean loss = 0.015721645\n","Start of epoch 200\n","step 0: mean loss = 0.015718268\n","step 100: mean loss = 0.015714375\n","step 200: mean loss = 0.015709748\n","Start of epoch 201\n","step 0: mean loss = 0.015706185\n","step 100: mean loss = 0.015702343\n","step 200: mean loss = 0.015698109\n","Start of epoch 202\n","step 0: mean loss = 0.015694628\n","step 100: mean loss = 0.015690945\n","step 200: mean loss = 0.015686972\n","Start of epoch 203\n","step 0: mean loss = 0.015683532\n","step 100: mean loss = 0.015680052\n","step 200: mean loss = 0.015675815\n","Start of epoch 204\n","step 0: mean loss = 0.015671901\n","step 100: mean loss = 0.015668672\n","step 200: mean loss = 0.015663741\n","Start of epoch 205\n","step 0: mean loss = 0.015660577\n","step 100: mean loss = 0.01565719\n","step 200: mean loss = 0.015652472\n","Start of epoch 206\n","step 0: mean loss = 0.01564881\n","step 100: mean loss = 0.015645646\n","step 200: mean loss = 0.015641253\n","Start of epoch 207\n","step 0: mean loss = 0.015637288\n","step 100: mean loss = 0.015633678\n","step 200: mean loss = 0.015629305\n","Start of epoch 208\n","step 0: mean loss = 0.015625527\n","step 100: mean loss = 0.015622399\n","step 200: mean loss = 0.015617969\n","Start of epoch 209\n","step 0: mean loss = 0.015614429\n","step 100: mean loss = 0.015611327\n","step 200: mean loss = 0.015606958\n","Start of epoch 210\n","step 0: mean loss = 0.015602988\n","step 100: mean loss = 0.015599042\n","step 200: mean loss = 0.015594656\n","Start of epoch 211\n","step 0: mean loss = 0.0155914165\n","step 100: mean loss = 0.0155878365\n","step 200: mean loss = 0.015583383\n","Start of epoch 212\n","step 0: mean loss = 0.015579767\n","step 100: mean loss = 0.015576754\n","step 200: mean loss = 0.015572074\n","Start of epoch 213\n","step 0: mean loss = 0.015568524\n","step 100: mean loss = 0.015565034\n","step 200: mean loss = 0.015560937\n","Start of epoch 214\n","step 0: mean loss = 0.015556948\n","step 100: mean loss = 0.015553515\n","step 200: mean loss = 0.015549079\n","Start of epoch 215\n","step 0: mean loss = 0.015545519\n","step 100: mean loss = 0.015542145\n","step 200: mean loss = 0.015537643\n","Start of epoch 216\n","step 0: mean loss = 0.015534077\n","step 100: mean loss = 0.015530798\n","step 200: mean loss = 0.015526728\n","Start of epoch 217\n","step 0: mean loss = 0.015523492\n","step 100: mean loss = 0.015520051\n","step 200: mean loss = 0.015516198\n","Start of epoch 218\n","step 0: mean loss = 0.015512515\n","step 100: mean loss = 0.015509164\n","step 200: mean loss = 0.015505112\n","Start of epoch 219\n","step 0: mean loss = 0.015502125\n","step 100: mean loss = 0.015498725\n","step 200: mean loss = 0.015494618\n","Start of epoch 220\n","step 0: mean loss = 0.015490763\n","step 100: mean loss = 0.015487202\n","step 200: mean loss = 0.015482904\n","Start of epoch 221\n","step 0: mean loss = 0.0154795945\n","step 100: mean loss = 0.015476225\n","step 200: mean loss = 0.01547256\n","Start of epoch 222\n","step 0: mean loss = 0.015469063\n","step 100: mean loss = 0.015465933\n","step 200: mean loss = 0.0154619925\n","Start of epoch 223\n","step 0: mean loss = 0.015458718\n","step 100: mean loss = 0.0154552385\n","step 200: mean loss = 0.015451141\n","Start of epoch 224\n","step 0: mean loss = 0.015447906\n","step 100: mean loss = 0.015444506\n","step 200: mean loss = 0.015440487\n","Start of epoch 225\n","step 0: mean loss = 0.015437683\n","step 100: mean loss = 0.015434415\n","step 200: mean loss = 0.015431066\n","Start of epoch 226\n","step 0: mean loss = 0.01542817\n","step 100: mean loss = 0.015425337\n","step 200: mean loss = 0.015421448\n","Start of epoch 227\n","step 0: mean loss = 0.015417941\n","step 100: mean loss = 0.015414852\n","step 200: mean loss = 0.015410955\n","Start of epoch 228\n","step 0: mean loss = 0.0154068945\n","step 100: mean loss = 0.015403795\n","step 200: mean loss = 0.015399401\n","Start of epoch 229\n","step 0: mean loss = 0.015395862\n","step 100: mean loss = 0.015392985\n","step 200: mean loss = 0.0153892245\n","Start of epoch 230\n","step 0: mean loss = 0.015386233\n","step 100: mean loss = 0.01538303\n","step 200: mean loss = 0.015378901\n","Start of epoch 231\n","step 0: mean loss = 0.015375375\n","step 100: mean loss = 0.015372042\n","step 200: mean loss = 0.015368008\n","Start of epoch 232\n","step 0: mean loss = 0.015364893\n","step 100: mean loss = 0.015361477\n","step 200: mean loss = 0.015357245\n","Start of epoch 233\n","step 0: mean loss = 0.015354333\n","step 100: mean loss = 0.015351164\n","step 200: mean loss = 0.015346997\n","Start of epoch 234\n","step 0: mean loss = 0.015343842\n","step 100: mean loss = 0.015340287\n","step 200: mean loss = 0.015336495\n","Start of epoch 235\n","step 0: mean loss = 0.015333402\n","step 100: mean loss = 0.015330004\n","step 200: mean loss = 0.01532634\n","Start of epoch 236\n","step 0: mean loss = 0.015322943\n","step 100: mean loss = 0.015319837\n","step 200: mean loss = 0.015316068\n","Start of epoch 237\n","step 0: mean loss = 0.015312769\n","step 100: mean loss = 0.015309454\n","step 200: mean loss = 0.015305241\n","Start of epoch 238\n","step 0: mean loss = 0.015302033\n","step 100: mean loss = 0.015298787\n","step 200: mean loss = 0.015294962\n","Start of epoch 239\n","step 0: mean loss = 0.015291767\n","step 100: mean loss = 0.0152884815\n","step 200: mean loss = 0.015284929\n","Start of epoch 240\n","step 0: mean loss = 0.015281527\n","step 100: mean loss = 0.015278431\n","step 200: mean loss = 0.015275213\n","Start of epoch 241\n","step 0: mean loss = 0.015272347\n","step 100: mean loss = 0.015269169\n","step 200: mean loss = 0.015265311\n","Start of epoch 242\n","step 0: mean loss = 0.015262092\n","step 100: mean loss = 0.015258486\n","step 200: mean loss = 0.015254921\n","Start of epoch 243\n","step 0: mean loss = 0.015251998\n","step 100: mean loss = 0.015249025\n","step 200: mean loss = 0.015245354\n","Start of epoch 244\n","step 0: mean loss = 0.0152423885\n","step 100: mean loss = 0.015238839\n","step 200: mean loss = 0.015235202\n","Start of epoch 245\n","step 0: mean loss = 0.015231939\n","step 100: mean loss = 0.015229035\n","step 200: mean loss = 0.015225452\n","Start of epoch 246\n","step 0: mean loss = 0.015222073\n","step 100: mean loss = 0.015219281\n","step 200: mean loss = 0.015215984\n","Start of epoch 247\n","step 0: mean loss = 0.015213077\n","step 100: mean loss = 0.015209826\n","step 200: mean loss = 0.015206184\n","Start of epoch 248\n","step 0: mean loss = 0.015203193\n","step 100: mean loss = 0.01520041\n","step 200: mean loss = 0.015196759\n","Start of epoch 249\n","step 0: mean loss = 0.015193742\n","step 100: mean loss = 0.015191015\n","step 200: mean loss = 0.015187242\n","Start of epoch 250\n","step 0: mean loss = 0.015184304\n","step 100: mean loss = 0.015181637\n","step 200: mean loss = 0.015178217\n","Start of epoch 251\n","step 0: mean loss = 0.015175046\n","step 100: mean loss = 0.015172068\n","step 200: mean loss = 0.0151687935\n","Start of epoch 252\n","step 0: mean loss = 0.015166081\n","step 100: mean loss = 0.015163029\n","step 200: mean loss = 0.015159499\n","Start of epoch 253\n","step 0: mean loss = 0.015156552\n","step 100: mean loss = 0.015153403\n","step 200: mean loss = 0.015149838\n","Start of epoch 254\n","step 0: mean loss = 0.015146956\n","step 100: mean loss = 0.015144248\n","step 200: mean loss = 0.0151403705\n","Start of epoch 255\n","step 0: mean loss = 0.01513733\n","step 100: mean loss = 0.015134062\n","step 200: mean loss = 0.01513065\n","Start of epoch 256\n","step 0: mean loss = 0.015127439\n","step 100: mean loss = 0.015124324\n","step 200: mean loss = 0.015121068\n","Start of epoch 257\n","step 0: mean loss = 0.015118053\n","step 100: mean loss = 0.015115324\n","step 200: mean loss = 0.015111839\n","Start of epoch 258\n","step 0: mean loss = 0.015109188\n","step 100: mean loss = 0.015106528\n","step 200: mean loss = 0.015102961\n","Start of epoch 259\n","step 0: mean loss = 0.01510005\n","step 100: mean loss = 0.015096861\n","step 200: mean loss = 0.015093197\n","Start of epoch 260\n","step 0: mean loss = 0.015090455\n","step 100: mean loss = 0.015087498\n","step 200: mean loss = 0.015084328\n","Start of epoch 261\n","step 0: mean loss = 0.015081468\n","step 100: mean loss = 0.015077956\n","step 200: mean loss = 0.015074421\n","Start of epoch 262\n","step 0: mean loss = 0.015071547\n","step 100: mean loss = 0.015068693\n","step 200: mean loss = 0.015065084\n","Start of epoch 263\n","step 0: mean loss = 0.015062528\n","step 100: mean loss = 0.01506006\n","step 200: mean loss = 0.015056881\n","Start of epoch 264\n","step 0: mean loss = 0.015054014\n","step 100: mean loss = 0.015051534\n","step 200: mean loss = 0.015048034\n","Start of epoch 265\n","step 0: mean loss = 0.015045275\n","step 100: mean loss = 0.015042637\n","step 200: mean loss = 0.015039188\n","Start of epoch 266\n","step 0: mean loss = 0.015036614\n","step 100: mean loss = 0.015034002\n","step 200: mean loss = 0.0150308395\n","Start of epoch 267\n","step 0: mean loss = 0.015028172\n","step 100: mean loss = 0.015025041\n","step 200: mean loss = 0.015021873\n","Start of epoch 268\n","step 0: mean loss = 0.015018999\n","step 100: mean loss = 0.015016796\n","step 200: mean loss = 0.015013468\n","Start of epoch 269\n","step 0: mean loss = 0.015010733\n","step 100: mean loss = 0.015007716\n","step 200: mean loss = 0.015004762\n","Start of epoch 270\n","step 0: mean loss = 0.0150022805\n","step 100: mean loss = 0.015000052\n","step 200: mean loss = 0.01499648\n","Start of epoch 271\n","step 0: mean loss = 0.0149939265\n","step 100: mean loss = 0.014991483\n","step 200: mean loss = 0.01498768\n","Start of epoch 272\n","step 0: mean loss = 0.014985073\n","step 100: mean loss = 0.014982254\n","step 200: mean loss = 0.014978896\n","Start of epoch 273\n","step 0: mean loss = 0.01497621\n","step 100: mean loss = 0.014973425\n","step 200: mean loss = 0.014969963\n","Start of epoch 274\n","step 0: mean loss = 0.014967214\n","step 100: mean loss = 0.014964724\n","step 200: mean loss = 0.014961465\n","Start of epoch 275\n","step 0: mean loss = 0.01495888\n","step 100: mean loss = 0.014955921\n","step 200: mean loss = 0.014952724\n","Start of epoch 276\n","step 0: mean loss = 0.014949928\n","step 100: mean loss = 0.014947796\n","step 200: mean loss = 0.014944217\n","Start of epoch 277\n","step 0: mean loss = 0.014941459\n","step 100: mean loss = 0.014939256\n","step 200: mean loss = 0.014935931\n","Start of epoch 278\n","step 0: mean loss = 0.01493359\n","step 100: mean loss = 0.01493073\n","step 200: mean loss = 0.014927081\n","Start of epoch 279\n","step 0: mean loss = 0.014924132\n","step 100: mean loss = 0.0149214715\n","step 200: mean loss = 0.014918446\n","Start of epoch 280\n","step 0: mean loss = 0.014916128\n","step 100: mean loss = 0.01491378\n","step 200: mean loss = 0.014911027\n","Start of epoch 281\n","step 0: mean loss = 0.014908332\n","step 100: mean loss = 0.014905976\n","step 200: mean loss = 0.0149029875\n","Start of epoch 282\n","step 0: mean loss = 0.014900374\n","step 100: mean loss = 0.014898062\n","step 200: mean loss = 0.014894775\n","Start of epoch 283\n","step 0: mean loss = 0.014891713\n","step 100: mean loss = 0.014889096\n","step 200: mean loss = 0.014886045\n","Start of epoch 284\n","step 0: mean loss = 0.0148834\n","step 100: mean loss = 0.014880489\n","step 200: mean loss = 0.01487725\n","Start of epoch 285\n","step 0: mean loss = 0.014874712\n","step 100: mean loss = 0.01487225\n","step 200: mean loss = 0.014869492\n","Start of epoch 286\n","step 0: mean loss = 0.014867292\n","step 100: mean loss = 0.014864571\n","step 200: mean loss = 0.01486134\n","Start of epoch 287\n","step 0: mean loss = 0.01485903\n","step 100: mean loss = 0.0148565015\n","step 200: mean loss = 0.014854064\n","Start of epoch 288\n","step 0: mean loss = 0.014851471\n","step 100: mean loss = 0.014849222\n","step 200: mean loss = 0.014845697\n","Start of epoch 289\n","step 0: mean loss = 0.014843074\n","step 100: mean loss = 0.014840408\n","step 200: mean loss = 0.014836872\n","Start of epoch 290\n","step 0: mean loss = 0.014834138\n","step 100: mean loss = 0.014831372\n","step 200: mean loss = 0.0148282\n","Start of epoch 291\n","step 0: mean loss = 0.014826381\n","step 100: mean loss = 0.014824035\n","step 200: mean loss = 0.014821389\n","Start of epoch 292\n","step 0: mean loss = 0.014818702\n","step 100: mean loss = 0.014816309\n","step 200: mean loss = 0.014813314\n","Start of epoch 293\n","step 0: mean loss = 0.014810631\n","step 100: mean loss = 0.014807948\n","step 200: mean loss = 0.014805409\n","Start of epoch 294\n","step 0: mean loss = 0.014802993\n","step 100: mean loss = 0.014800277\n","step 200: mean loss = 0.014797046\n","Start of epoch 295\n","step 0: mean loss = 0.014794582\n","step 100: mean loss = 0.014792417\n","step 200: mean loss = 0.014789378\n","Start of epoch 296\n","step 0: mean loss = 0.014786849\n","step 100: mean loss = 0.014784277\n","step 200: mean loss = 0.014781133\n","Start of epoch 297\n","step 0: mean loss = 0.014778579\n","step 100: mean loss = 0.014776266\n","step 200: mean loss = 0.014773252\n","Start of epoch 298\n","step 0: mean loss = 0.014770937\n","step 100: mean loss = 0.014768419\n","step 200: mean loss = 0.014765303\n","Start of epoch 299\n","step 0: mean loss = 0.014763189\n","step 100: mean loss = 0.01476036\n","step 200: mean loss = 0.01475758\n","Start of epoch 300\n","step 0: mean loss = 0.014755207\n","step 100: mean loss = 0.014752798\n","step 200: mean loss = 0.014750174\n","Start of epoch 301\n","step 0: mean loss = 0.014747454\n","step 100: mean loss = 0.014745186\n","step 200: mean loss = 0.014742024\n","Start of epoch 302\n","step 0: mean loss = 0.014739554\n","step 100: mean loss = 0.014737049\n","step 200: mean loss = 0.0147341965\n","Start of epoch 303\n","step 0: mean loss = 0.014731624\n","step 100: mean loss = 0.014729075\n","step 200: mean loss = 0.014726508\n","Start of epoch 304\n","step 0: mean loss = 0.01472369\n","step 100: mean loss = 0.014721295\n","step 200: mean loss = 0.014718558\n","Start of epoch 305\n","step 0: mean loss = 0.014715849\n","step 100: mean loss = 0.014713656\n","step 200: mean loss = 0.014710425\n","Start of epoch 306\n","step 0: mean loss = 0.014708045\n","step 100: mean loss = 0.01470565\n","step 200: mean loss = 0.014702354\n","Start of epoch 307\n","step 0: mean loss = 0.014700103\n","step 100: mean loss = 0.014697943\n","step 200: mean loss = 0.014695082\n","Start of epoch 308\n","step 0: mean loss = 0.014692813\n","step 100: mean loss = 0.014690128\n","step 200: mean loss = 0.014687021\n","Start of epoch 309\n","step 0: mean loss = 0.014684246\n","step 100: mean loss = 0.014681768\n","step 200: mean loss = 0.01467883\n","Start of epoch 310\n","step 0: mean loss = 0.014676323\n","step 100: mean loss = 0.014673938\n","step 200: mean loss = 0.014671141\n","Start of epoch 311\n","step 0: mean loss = 0.014669126\n","step 100: mean loss = 0.014666906\n","step 200: mean loss = 0.014663796\n","Start of epoch 312\n","step 0: mean loss = 0.0146615\n","step 100: mean loss = 0.0146593135\n","step 200: mean loss = 0.014656512\n","Start of epoch 313\n","step 0: mean loss = 0.01465445\n","step 100: mean loss = 0.014651722\n","step 200: mean loss = 0.014649055\n","Start of epoch 314\n","step 0: mean loss = 0.014646475\n","step 100: mean loss = 0.014644227\n","step 200: mean loss = 0.014641484\n","Start of epoch 315\n","step 0: mean loss = 0.0146393\n","step 100: mean loss = 0.014637131\n","step 200: mean loss = 0.01463434\n","Start of epoch 316\n","step 0: mean loss = 0.014631939\n","step 100: mean loss = 0.014629934\n","step 200: mean loss = 0.014626947\n","Start of epoch 317\n","step 0: mean loss = 0.014624486\n","step 100: mean loss = 0.014622313\n","step 200: mean loss = 0.014619158\n","Start of epoch 318\n","step 0: mean loss = 0.01461666\n","step 100: mean loss = 0.014614225\n","step 200: mean loss = 0.014611434\n","Start of epoch 319\n","step 0: mean loss = 0.014609121\n","step 100: mean loss = 0.014606963\n","step 200: mean loss = 0.0146041615\n","Start of epoch 320\n","step 0: mean loss = 0.014601827\n","step 100: mean loss = 0.014599359\n","step 200: mean loss = 0.014596673\n","Start of epoch 321\n","step 0: mean loss = 0.0145945875\n","step 100: mean loss = 0.01459207\n","step 200: mean loss = 0.014589292\n","Start of epoch 322\n","step 0: mean loss = 0.014587341\n","step 100: mean loss = 0.014585312\n","step 200: mean loss = 0.014582906\n","Start of epoch 323\n","step 0: mean loss = 0.014580978\n","step 100: mean loss = 0.014578991\n","step 200: mean loss = 0.014576145\n","Start of epoch 324\n","step 0: mean loss = 0.014573643\n","step 100: mean loss = 0.014571587\n","step 200: mean loss = 0.014569122\n","Start of epoch 325\n","step 0: mean loss = 0.014566825\n","step 100: mean loss = 0.014564236\n","step 200: mean loss = 0.014561789\n","Start of epoch 326\n","step 0: mean loss = 0.014559555\n","step 100: mean loss = 0.014557436\n","step 200: mean loss = 0.014554688\n","Start of epoch 327\n","step 0: mean loss = 0.014552599\n","step 100: mean loss = 0.014550333\n","step 200: mean loss = 0.0145474905\n","Start of epoch 328\n","step 0: mean loss = 0.014545466\n","step 100: mean loss = 0.014543511\n","step 200: mean loss = 0.014541161\n","Start of epoch 329\n","step 0: mean loss = 0.014539221\n","step 100: mean loss = 0.014537259\n","step 200: mean loss = 0.014534485\n","Start of epoch 330\n","step 0: mean loss = 0.0145323435\n","step 100: mean loss = 0.014530301\n","step 200: mean loss = 0.014527885\n","Start of epoch 331\n","step 0: mean loss = 0.014526129\n","step 100: mean loss = 0.014524022\n","step 200: mean loss = 0.014521162\n","Start of epoch 332\n","step 0: mean loss = 0.014518507\n","step 100: mean loss = 0.014516509\n","step 200: mean loss = 0.014513997\n","Start of epoch 333\n","step 0: mean loss = 0.014512331\n","step 100: mean loss = 0.014510324\n","step 200: mean loss = 0.014507678\n","Start of epoch 334\n","step 0: mean loss = 0.014505515\n","step 100: mean loss = 0.014503288\n","step 200: mean loss = 0.014500478\n","Start of epoch 335\n","step 0: mean loss = 0.01449827\n","step 100: mean loss = 0.014496281\n","step 200: mean loss = 0.01449358\n","Start of epoch 336\n","step 0: mean loss = 0.01449157\n","step 100: mean loss = 0.014489225\n","step 200: mean loss = 0.014486446\n","Start of epoch 337\n","step 0: mean loss = 0.0144849485\n","step 100: mean loss = 0.014482731\n","step 200: mean loss = 0.014480163\n","Start of epoch 338\n","step 0: mean loss = 0.0144782225\n","step 100: mean loss = 0.014476236\n","step 200: mean loss = 0.014473349\n","Start of epoch 339\n","step 0: mean loss = 0.014471524\n","step 100: mean loss = 0.014469743\n","step 200: mean loss = 0.014467105\n","Start of epoch 340\n","step 0: mean loss = 0.014465054\n","step 100: mean loss = 0.014462994\n","step 200: mean loss = 0.014460833\n","Start of epoch 341\n","step 0: mean loss = 0.014458533\n","step 100: mean loss = 0.014456437\n","step 200: mean loss = 0.014454089\n","Start of epoch 342\n","step 0: mean loss = 0.014451802\n","step 100: mean loss = 0.014449764\n","step 200: mean loss = 0.0144470865\n","Start of epoch 343\n","step 0: mean loss = 0.014444969\n","step 100: mean loss = 0.014443063\n","step 200: mean loss = 0.014439992\n","Start of epoch 344\n","step 0: mean loss = 0.014438119\n","step 100: mean loss = 0.014435684\n","step 200: mean loss = 0.014432954\n","Start of epoch 345\n","step 0: mean loss = 0.01443115\n","step 100: mean loss = 0.014429402\n","step 200: mean loss = 0.014426998\n","Start of epoch 346\n","step 0: mean loss = 0.0144250095\n","step 100: mean loss = 0.014422964\n","step 200: mean loss = 0.014420582\n","Start of epoch 347\n","step 0: mean loss = 0.014418436\n","step 100: mean loss = 0.014416433\n","step 200: mean loss = 0.014413657\n","Start of epoch 348\n","step 0: mean loss = 0.014411294\n","step 100: mean loss = 0.0144093335\n","step 200: mean loss = 0.014406544\n","Start of epoch 349\n","step 0: mean loss = 0.014404077\n","step 100: mean loss = 0.014401838\n","step 200: mean loss = 0.014399237\n","Start of epoch 350\n","step 0: mean loss = 0.014396926\n","step 100: mean loss = 0.014395069\n","step 200: mean loss = 0.014392444\n","Start of epoch 351\n","step 0: mean loss = 0.014390593\n","step 100: mean loss = 0.014388172\n","step 200: mean loss = 0.014385981\n","Start of epoch 352\n","step 0: mean loss = 0.014384215\n","step 100: mean loss = 0.014382308\n","step 200: mean loss = 0.014379578\n","Start of epoch 353\n","step 0: mean loss = 0.014377043\n","step 100: mean loss = 0.014374992\n","step 200: mean loss = 0.014372212\n","Start of epoch 354\n","step 0: mean loss = 0.01437004\n","step 100: mean loss = 0.014367643\n","step 200: mean loss = 0.0143654505\n","Start of epoch 355\n","step 0: mean loss = 0.014363449\n","step 100: mean loss = 0.014361523\n","step 200: mean loss = 0.01435891\n","Start of epoch 356\n","step 0: mean loss = 0.014357319\n","step 100: mean loss = 0.01435514\n","step 200: mean loss = 0.014353052\n","Start of epoch 357\n","step 0: mean loss = 0.0143509945\n","step 100: mean loss = 0.014349098\n","step 200: mean loss = 0.014346604\n","Start of epoch 358\n","step 0: mean loss = 0.014344815\n","step 100: mean loss = 0.014342685\n","step 200: mean loss = 0.0143404035\n","Start of epoch 359\n","step 0: mean loss = 0.014338674\n","step 100: mean loss = 0.014336906\n","step 200: mean loss = 0.014334773\n","Start of epoch 360\n","step 0: mean loss = 0.0143326\n","step 100: mean loss = 0.014330461\n","step 200: mean loss = 0.014328192\n","Start of epoch 361\n","step 0: mean loss = 0.014326538\n","step 100: mean loss = 0.014324552\n","step 200: mean loss = 0.014321887\n","Start of epoch 362\n","step 0: mean loss = 0.014319965\n","step 100: mean loss = 0.014318015\n","step 200: mean loss = 0.014315609\n","Start of epoch 363\n","step 0: mean loss = 0.014313445\n","step 100: mean loss = 0.014311717\n","step 200: mean loss = 0.014308873\n","Start of epoch 364\n","step 0: mean loss = 0.014307232\n","step 100: mean loss = 0.014304911\n","step 200: mean loss = 0.014302642\n","Start of epoch 365\n","step 0: mean loss = 0.014300832\n","step 100: mean loss = 0.01429917\n","step 200: mean loss = 0.01429677\n","Start of epoch 366\n","step 0: mean loss = 0.01429476\n","step 100: mean loss = 0.014293067\n","step 200: mean loss = 0.014290448\n","Start of epoch 367\n","step 0: mean loss = 0.014288423\n","step 100: mean loss = 0.01428629\n","step 200: mean loss = 0.014283591\n","Start of epoch 368\n","step 0: mean loss = 0.014281585\n","step 100: mean loss = 0.01427985\n","step 200: mean loss = 0.014277762\n","Start of epoch 369\n","step 0: mean loss = 0.014275785\n","step 100: mean loss = 0.014274166\n","step 200: mean loss = 0.014271863\n","Start of epoch 370\n","step 0: mean loss = 0.014270161\n","step 100: mean loss = 0.014268498\n","step 200: mean loss = 0.014265987\n","Start of epoch 371\n","step 0: mean loss = 0.014263789\n","step 100: mean loss = 0.014261809\n","step 200: mean loss = 0.014259676\n","Start of epoch 372\n","step 0: mean loss = 0.014257769\n","step 100: mean loss = 0.014255864\n","step 200: mean loss = 0.014253188\n","Start of epoch 373\n","step 0: mean loss = 0.014251247\n","step 100: mean loss = 0.014249674\n","step 200: mean loss = 0.014247145\n","Start of epoch 374\n","step 0: mean loss = 0.014245376\n","step 100: mean loss = 0.014243624\n","step 200: mean loss = 0.014241122\n","Start of epoch 375\n","step 0: mean loss = 0.014239351\n","step 100: mean loss = 0.014237542\n","step 200: mean loss = 0.014234967\n","Start of epoch 376\n","step 0: mean loss = 0.0142330425\n","step 100: mean loss = 0.014231054\n","step 200: mean loss = 0.014228619\n","Start of epoch 377\n","step 0: mean loss = 0.014227022\n","step 100: mean loss = 0.014225528\n","step 200: mean loss = 0.014222874\n","Start of epoch 378\n","step 0: mean loss = 0.014221028\n","step 100: mean loss = 0.0142193055\n","step 200: mean loss = 0.014217139\n","Start of epoch 379\n","step 0: mean loss = 0.014215454\n","step 100: mean loss = 0.014213649\n","step 200: mean loss = 0.014211149\n","Start of epoch 380\n","step 0: mean loss = 0.014209413\n","step 100: mean loss = 0.014207966\n","step 200: mean loss = 0.014205719\n","Start of epoch 381\n","step 0: mean loss = 0.014203718\n","step 100: mean loss = 0.014201638\n","step 200: mean loss = 0.014199063\n","Start of epoch 382\n","step 0: mean loss = 0.014197464\n","step 100: mean loss = 0.014195619\n","step 200: mean loss = 0.0141931\n","Start of epoch 383\n","step 0: mean loss = 0.014191408\n","step 100: mean loss = 0.01418984\n","step 200: mean loss = 0.01418733\n","Start of epoch 384\n","step 0: mean loss = 0.014185655\n","step 100: mean loss = 0.014183698\n","step 200: mean loss = 0.014181349\n","Start of epoch 385\n","step 0: mean loss = 0.014179894\n","step 100: mean loss = 0.01417835\n","step 200: mean loss = 0.014176006\n","Start of epoch 386\n","step 0: mean loss = 0.014174408\n","step 100: mean loss = 0.01417262\n","step 200: mean loss = 0.01417016\n","Start of epoch 387\n","step 0: mean loss = 0.014168345\n","step 100: mean loss = 0.014166551\n","step 200: mean loss = 0.0141642485\n","Start of epoch 388\n","step 0: mean loss = 0.01416249\n","step 100: mean loss = 0.014160807\n","step 200: mean loss = 0.014158544\n","Start of epoch 389\n","step 0: mean loss = 0.014156512\n","step 100: mean loss = 0.014154958\n","step 200: mean loss = 0.014152987\n","Start of epoch 390\n","step 0: mean loss = 0.014151172\n","step 100: mean loss = 0.014149267\n","step 200: mean loss = 0.014146824\n","Start of epoch 391\n","step 0: mean loss = 0.014144799\n","step 100: mean loss = 0.014142927\n","step 200: mean loss = 0.014140893\n","Start of epoch 392\n","step 0: mean loss = 0.014139064\n","step 100: mean loss = 0.01413729\n","step 200: mean loss = 0.0141353635\n","Start of epoch 393\n","step 0: mean loss = 0.0141331665\n","step 100: mean loss = 0.014131617\n","step 200: mean loss = 0.014129054\n","Start of epoch 394\n","step 0: mean loss = 0.014127264\n","step 100: mean loss = 0.014125926\n","step 200: mean loss = 0.0141236\n","Start of epoch 395\n","step 0: mean loss = 0.014121846\n","step 100: mean loss = 0.014120166\n","step 200: mean loss = 0.01411794\n","Start of epoch 396\n","step 0: mean loss = 0.014116109\n","step 100: mean loss = 0.014114754\n","step 200: mean loss = 0.014112635\n","Start of epoch 397\n","step 0: mean loss = 0.014110544\n","step 100: mean loss = 0.014108923\n","step 200: mean loss = 0.014106809\n","Start of epoch 398\n","step 0: mean loss = 0.01410478\n","step 100: mean loss = 0.014102938\n","step 200: mean loss = 0.0141010955\n","Start of epoch 399\n","step 0: mean loss = 0.0140991695\n","step 100: mean loss = 0.014097062\n","step 200: mean loss = 0.014094777\n"],"name":"stdout"}]},{"metadata":{"id":"N5mepDBDz1sW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":269},"outputId":"edfcc748-f7e4-433e-d637-4b91686e09ba","executionInfo":{"status":"ok","timestamp":1556030127636,"user_tz":-330,"elapsed":928,"user":{"displayName":"chhaya kumar das","photoUrl":"https://lh4.googleusercontent.com/-72S0CIJmkNQ/AAAAAAAAAAI/AAAAAAAAAP4/TOqLaMhUrd8/s64/photo.jpg","userId":"05135137199177257776"}}},"cell_type":"code","source":["samp = imgs[0].astype('float32')\n","noi_p = samp + 0.5*np.random.randn(*samp.shape)\n","noi_p = np.clip(noi_p,0.,1.)\n","plt.imshow(np.squeeze(noi_p,axis=2),cmap='gray')\n","plt.show()\n","\n"],"execution_count":44,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"IW6y9mz0Dube","colab_type":"code","outputId":"8a0c20a2-dea0-4190-85e5-99c8bc12e6de","executionInfo":{"status":"ok","timestamp":1556030131412,"user_tz":-330,"elapsed":888,"user":{"displayName":"chhaya kumar das","photoUrl":"https://lh4.googleusercontent.com/-72S0CIJmkNQ/AAAAAAAAAAI/AAAAAAAAAP4/TOqLaMhUrd8/s64/photo.jpg","userId":"05135137199177257776"}},"colab":{"base_uri":"https://localhost:8080/","height":269}},"cell_type":"code","source":["plt.imshow(np.squeeze(imgs[0],axis=2),cmap='gray')\n","plt.show()\n"],"execution_count":45,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+9SdQQAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"qehQg2ww6I1w","colab_type":"code","outputId":"55f2bb12-c330-478a-d823-16b198072a42","executionInfo":{"status":"ok","timestamp":1556030133486,"user_tz":-330,"elapsed":802,"user":{"displayName":"chhaya kumar das","photoUrl":"https://lh4.googleusercontent.com/-72S0CIJmkNQ/AAAAAAAAAAI/AAAAAAAAAP4/TOqLaMhUrd8/s64/photo.jpg","userId":"05135137199177257776"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["noi_p = np.expand_dims(noi_p,axis=0)\n","noi_p.shape"],"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 28, 28, 1)"]},"metadata":{"tags":[]},"execution_count":46}]},{"metadata":{"id":"-1VLVRcaDrOX","colab_type":"code","colab":{}},"cell_type":"code","source":["#noi_p = noi_p.astype('float32')\n","pred = ae(noi_p)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rPpjZTcr4A6W","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":269},"outputId":"a0e1a1e8-e0e0-49a7-bd8c-d5f1796697eb","executionInfo":{"status":"ok","timestamp":1556030136639,"user_tz":-330,"elapsed":816,"user":{"displayName":"chhaya kumar das","photoUrl":"https://lh4.googleusercontent.com/-72S0CIJmkNQ/AAAAAAAAAAI/AAAAAAAAAP4/TOqLaMhUrd8/s64/photo.jpg","userId":"05135137199177257776"}}},"cell_type":"code","source":["plt.imshow(np.squeeze(pred[0],axis=2),cmap='gray')\n","plt.show()"],"execution_count":48,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAE25JREFUeJzt3W+MlfWVB/Dv4Z+M/JGZAYdxGJQl\nRkF06WZCNqnZdO2WCGmCjYkpLxo2MaUvarJN+mKN+0LfmJjNto0vNk2mKyluurabtEZijIvFjVqy\nVgbDIlZXRwMy48DAIDLAIMzM2RfzYEad55w79/fc57n0fD8JYbjn/p7nd597D3fuPb8/oqogonjm\nVN0BIqoGk58oKCY/UVBMfqKgmPxEQTH5iYJi8hMFxeQnCorJTxTUvDJP1t7ert3d3XW3b+RoRBGp\n+9xe2yqlPK4iVDmCtMpzz5lTzfvq8ePHMTIyUtMLMin5ReReAE8CmAvg31T1Cev+3d3dePnll3Pj\nExMT5vkmJyfrbuuZN8++FNYLKaVtLVISeO7cuWZb65p6x64lbj0v3uPy+uZJeU14bb3r2tLSYsat\nx+Yd23LPPffUfN+6/3sSkbkA/hXAFgDrAWwXkfX1Ho+IypXyu8kmAP2q+qGqXgbwawDbiukWETVa\nSvJ3ATg+7d8D2W1fICI7RaRPRPpGRkYSTkdERWr4txKq2quqPara097e3ujTEVGNUpJ/EMD0r+5X\nZbcR0TUgJfkPALhVRNaIyAIA3wWwp5huEVGj1V3qU9VxEXkIwH9hqtS3S1XfttqIiFne8WqjKW29\nklRKuc4rC12+fDnp3CnX5cqVK2ZbT+p1tcpW3nVLvS4pxsfHzXhqCTWl76kl0KuS6vyq+gKAFwrp\nCRGVisN7iYJi8hMFxeQnCorJTxQUk58oKCY/UVClzudX1aRpuVZbrybs1Ua9uq5VS/dq3dddd50Z\nT502O3/+/NyYd01T6vSAPy23yrUOmnktAavO712zlLZfOE7N9ySiPytMfqKgmPxEQTH5iYJi8hMF\nxeQnCqrUUh9gl9xSSjOpJSmPNS03tVTnxb2+p65cbEmdPprynKaWEau8Lt7j9krL9R57Nteb7/xE\nQTH5iYJi8hMFxeQnCorJTxQUk58oKCY/UVCl1/lTliy26rbecS9cuGDGz549a8YvXbqUG/PqzW1t\nbWZ8yZIlZjxlemjqGIKUc3vtU5febmQdP1XKYytrmjTf+YmCYvITBcXkJwqKyU8UFJOfKCgmP1FQ\nTH6ioJLq/CJyFMAogAkA46raY91/zpw57jLWFqvW7jl8+LAZP3jwoBm36tU333yz2XbNmjVmvKOj\nw4xbS3MDwIIFC3Jj3vVO2f67FintU8cYWOMAUsc/NLIWnzr2olZFDPL5W1U9XcBxiKhE/LWfKKjU\n5FcAe0XkoIjsLKJDRFSO1F/771bVQRG5EcBLIvKuqr46/Q7Zfwo7AaC7uzvxdERUlKR3flUdzP4e\nBvAsgE0z3KdXVXtUtWf58uUppyOiAtWd/CKySESWXP0ZwGYAR4rqGBE1Vsqv/R0Ans3KEvMA/Ieq\nvlhIr4io4epOflX9EMBfzradVZu11sYH7LqtN19/7969Zry/v9+M33777bkxrw7vrfF+/vx5M97S\n0mLGrT0LvDnvqTXllHq3d10aub13yjoEQHm1+EYem6U+oqCY/ERBMfmJgmLyEwXF5CcKislPFFSp\nS3eLCObNyz/lmTNnzPZWaeiVV14x27722mtmfOvWrWZ8w4YNuTFve/CBgQEz7unq6jLjK1asyI15\n5bSFCxeaca8klloya1RbwC7HpZbqUvtmtefS3UTUUEx+oqCY/ERBMfmJgmLyEwXF5CcKislPFFSp\ndf6JiQlz+urY2JjZ3mq7f/9+s21ra6sZv//++824tY221+8PPvjAjB8/ftyMX7x40Yxb4wysZb0B\nfzqyV8f3xhGkbB+eunR3ikYvWZ4yToB1fiJKwuQnCorJTxQUk58oKCY/UVBMfqKgmPxEQZVa5wfs\n+qZXc7aWofa24N6yZYsZt+brA8Do6GhuzKt1e9tkd3Z2mvFjx46Z8VOnTtV97tT5+inbZKceu5Hb\nYHsaPd/fwjo/ESVh8hMFxeQnCorJTxQUk58oKCY/UVBMfqKg3Dq/iOwC8G0Aw6q6IbutDcBvANwC\n4CiAB1T1E+9Yc+bMMevOXl3XWvPfqnUDwG233Vb3sQF7C/Drr7/ebLts2TIz7m3B7dV1rXEAQ0ND\nZltvvr+1jkEt7a9cuWLGLSlrBQBp24N7UttbyhpDUMs7/y8B3Pul2x4GsE9VbwWwL/s3EV1D3ORX\n1VcBfHkrnW0Admc/7wZwX8H9IqIGq/czf4eqXv198gSAjoL6Q0QlSf7CT6c+gOR+CBGRnSLSJyJ9\np0+fTj0dERWk3uQ/KSKdAJD9PZx3R1XtVdUeVe1Zvnx5nacjoqLVm/x7AOzIft4B4LliukNEZXGT\nX0SeAfA/AG4TkQEReRDAEwC+JSLvA/i77N9EdA1x6/yquj0n9M3ZnkxEzDq/NfcbsGurw8O5nzwA\nAO3t7XbnHNZaA14d3quFe3XblStXmnFr3f4jR46YbQcGBsy4t9+BtwaD9di8sRWNnBOfyhtjkFKr\n98YQlFnnJ6I/Q0x+oqCY/ERBMfmJgmLyEwXF5CcKqtSlu0XELO9YJSsAGB8fz41ZS2sD/rRbb+qp\nVdJKnXqaurz2TTfdlBvztvd+9913zbhXjrvjjjvqbu8dO3V78KKWuK7n3CnluEYuWf6F8xRyFCK6\n5jD5iYJi8hMFxeQnCorJTxQUk58oKCY/UVCl1vlV1Zy2W+UUTmtpbsAeB+DV6b3H5dWMvbg1/sFb\nenvhwoVm/PXXXzfj3viK9evX58a8lZ28qdDeuBDrujd6eexGLu3tjQOo+TiFHIWIrjlMfqKgmPxE\nQTH5iYJi8hMFxeQnCorJTxRU6fP5rbnI3tLdVj3bmxvuSdlKOrVm7MUvX75sxj/77LPcmDef31sW\n/OzZs2b8xRdfNOMHDhzIjW3atMlsu27dOjPubX1uPafWawnw58x7rzdvjIK35LnFGkMwm/EJfOcn\nCorJTxQUk58oKCY/UVBMfqKgmPxEQTH5iYJyi+MisgvAtwEMq+qG7LbHAHwfwKnsbo+o6gu1nNCa\ni5yy/v3ixYvNtl7d1av7enPHLd74Ba8267W36tnefgXefP8bb7zRjK9evdqMv/HGG7mx559/3my7\nf/9+M97Z2WnGFy1alBvzHteKFSvqPjYALF261Ixbr1fvObNeL7NZ07+Wd/5fArh3htt/pqobsz81\nJT4RNQ83+VX1VQBnSugLEZUo5TP/QyJyWER2iUhrYT0iolLUm/w/B7AWwEYAQwB+kndHEdkpIn0i\n0nfq1Km8uxFRyepKflU9qaoTqjoJ4BcAcmdoqGqvqvaoao/3JQoRlaeu5BeR6V+zfgfAkWK6Q0Rl\nqaXU9wyAbwBYLiIDAB4F8A0R2QhAARwF8IMG9pGIGsBNflXdPsPNT9V7QquW781bt+rd3hgBb+53\nyhrw3hiB1L3cvTEK1r4B3hrvXtzr+6pVq8z4nXfemRs7duyY2dYb3+D13Zoz711Tr15uraEAAJ9+\n+qkZt3j7QMymlm/hCD+ioJj8REEx+YmCYvITBcXkJwqKyU8UVOlbdHtlMcvIyEhuzCv7eEste+2t\n8orX1ivleaUbr+RlleNSHhfgl528UqA1PXXt2rVm2/Pnz5tx77pY0269pbMvXbpkxgcHB824V7a2\npvx6OZKy7Pd0fOcnCorJTxQUk58oKCY/UVBMfqKgmPxEQTH5iYIqtc4/OTlpbhnt1Ubfe++93Fjq\nlF1PI2vpqVM0U8YgeLVy7znxWH3znhNvCWuv79YYBe/cqdO0vSm91tLh3nNWFL7zEwXF5CcKislP\nFBSTnygoJj9RUEx+oqCY/ERBlVrnFxFzXr1X77a2+1q5cqXZtqWlxYx7NWVrG2yvZuzVhD0p6wF4\nbVOXFfceuzVOwLqmADA2NmbGvb5b4wBS58R71+Xs2bNm3Fr6O/U5qxXf+YmCYvITBcXkJwqKyU8U\nFJOfKCgmP1FQTH6ioNw6v4h0A3gaQAcABdCrqk+KSBuA3wC4BcBRAA+o6ifWsSYnJ8310L2675Il\nS3JjnZ2dZltvfrYXt/rmzSv3NLIW742d8M7txb3nzOLV2lP3DEjhbcH98ccfm3Fv3f+U8S5lbtE9\nDuDHqroewF8D+KGIrAfwMIB9qnorgH3Zv4noGuEmv6oOqeqb2c+jAN4B0AVgG4Dd2d12A7ivUZ0k\nouLN6jO/iNwC4GsA/gigQ1WHstAJTH0sIKJrRM3JLyKLAfwWwI9U9dz0mE59MJzxw6GI7BSRPhHp\ns/baI6Jy1ZT8IjIfU4n/K1X9XXbzSRHpzOKdAIZnaquqvarao6o97e3tRfSZiArgJr9MfbX4FIB3\nVPWn00J7AOzIft4B4Lniu0dEjVLLlN6vA/gegLdE5FB22yMAngDwnyLyIIBjAB7wDqSqZlnMmwaZ\nUlbytnteuHChGbf67S21nFpmHB0dNePWY7tw4YLZ9ty5c2Y8ZXtwr31qqc+7blaZMnVZ8E8+Mava\naG1tNePWY0tdCr5WbvKr6h8A5J3tm4X0gohKxxF+REEx+YmCYvITBcXkJwqKyU8UFJOfKKjSl+62\napjWlF3Arndby3oDwEcffWTGvTq/VS/36tFeTdirxXvjH06fPp0b88Y3eOf2tuj26uHW1FZvjIBX\nz/amzaac23stevGuri4zbi15nrJU+2zwnZ8oKCY/UVBMfqKgmPxEQTH5iYJi8hMFxeQnCqrUOv+l\nS5fQ39+fG7fq1YA9/9urhT/66KNmfPPmzWZ8wYIFuTFve3BvG2tvnIA3BqGtrS03tnr1arOtN3fc\n29p80aJFZtx6zrz5/KnbaFtjFM6cOWO2PXHihBn3ntOlS5eacWvpbm+dgtTrchXf+YmCYvITBcXk\nJwqKyU8UFJOfKCgmP1FQTH6ioEqt86sqxsbGcuPe3PB169blxh5//HGzrbelslertyxbtiwp7q0h\n79V1re2kvWN7dX6PV++26tlWrBZe3619HryxFTfccIMZ99Y5WLx4sRlPeeypz9nnxynkKER0zWHy\nEwXF5CcKislPFBSTnygoJj9RUEx+oqDcYqOIdAN4GkAHAAXQq6pPishjAL4P4OqC+Y+o6gvWsVpa\nWnDXXXflxi9evGj2xapvenXTlJowYI9B8Grd3px4b3yDV1NOmTPv9d3jtbeuu7f+fOr69VYt33u9\neGsoeHPuvb5Zce+aetelVrWMNBgH8GNVfVNElgA4KCIvZbGfqeq/FNITIiqVm/yqOgRgKPt5VETe\nAWBvR0JETW9Wn/lF5BYAXwPwx+ymh0TksIjsEpHWnDY7RaRPRPpGRkaSOktExak5+UVkMYDfAviR\nqp4D8HMAawFsxNRvBj+ZqZ2q9qpqj6r2tLe3F9BlIipCTckvIvMxlfi/UtXfAYCqnlTVCVWdBPAL\nAJsa100iKpqb/DL1teRTAN5R1Z9Ou71z2t2+A+BI8d0jokap5dv+rwP4HoC3RORQdtsjALaLyEZM\nlf+OAviBdyBVNbdG9koYVknMm7rqlU+8kpjVt5QyIeCXhbzpoVYp0HvcqWUlb6trq733uL1je1Je\naymlulriKVOdvTJjrWr5tv8PAGZ6JGZNn4iaG0f4EQXF5CcKislPFBSTnygoJj9RUEx+oqBKXbp7\ncnIS586dy417yylb22R7dVWv1u7Vu71ptSltrccF+DXplC2bvWN7Yxi8Wrx1XYtagjqP95qwpIxf\nANKmSnvX3IrPZrov3/mJgmLyEwXF5CcKislPFBSTnygoJj9RUEx+oqCkqGWAazqZyCkAx6bdtBzA\n6dI6MDvN2rdm7RfAvtWryL7drKorarljqcn/lZOL9KlqT2UdMDRr35q1XwD7Vq+q+sZf+4mCYvIT\nBVV18vdWfH5Ls/atWfsFsG/1qqRvlX7mJ6LqVP3OT0QVqST5ReReEfk/EekXkYer6EMeETkqIm+J\nyCER6au4L7tEZFhEjky7rU1EXhKR97O/Z9wmraK+PSYig9m1OyQiWyvqW7eI/LeI/ElE3haRf8hu\nr/TaGf2q5LqV/mu/iMwF8B6AbwEYAHAAwHZV/VOpHckhIkcB9Khq5TVhEfkbAOcBPK2qG7Lb/hnA\nGVV9IvuPs1VV/7FJ+vYYgPNV79ycbSjTOX1naQD3Afh7VHjtjH49gAquWxXv/JsA9Kvqh6p6GcCv\nAWyroB9NT1VfBXDmSzdvA7A7+3k3pl48pcvpW1NQ1SFVfTP7eRTA1Z2lK712Rr8qUUXydwE4Pu3f\nA2iuLb8VwF4ROSgiO6vuzAw6sm3TAeAEgI4qOzMDd+fmMn1pZ+mmuXb17HhdNH7h91V3q+pfAdgC\n4IfZr7dNSac+szVTuaamnZvLMsPO0p+r8trVu+N10apI/kEA3dP+vSq7rSmo6mD29zCAZ9F8uw+f\nvLpJavb3cMX9+Vwz7dw8087SaIJr10w7XleR/AcA3Coia0RkAYDvAthTQT++QkQWZV/EQEQWAdiM\n5tt9eA+AHdnPOwA8V2FfvqBZdm7O21kaFV+7ptvxWlVL/wNgK6a+8f8AwD9V0Yecfv0FgP/N/rxd\ndd8APIOpXwOvYOq7kQcBtAPYB+B9AL8H0NZEfft3AG8BOIypROusqG93Y+pX+sMADmV/tlZ97Yx+\nVXLdOMKPKCh+4UcUFJOfKCgmP1FQTH6ioJj8REEx+YmCYvITBcXkJwrq/wGxgJV8XogbsgAAAABJ\nRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"KOEiguiq6QXw","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"hFHPgAcc38eq","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"Zfa2pPZonR_C","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"ypdl8lYmnUJO","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"W85Tf9ces66C","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"VtUsh_cPtZAC","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"2i4W02l-tpLy","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"zTG5BLJKucEq","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"k53SizWLunjM","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"Z0lWgAR48yBx","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"6LhOi2H89agZ","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"sXZnAvHB9cE5","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}